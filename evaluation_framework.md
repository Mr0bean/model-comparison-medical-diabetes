# LLM医疗病历信息提取评测方案

## 一、评测目标

评估7个LLM模型在医疗问诊记录信息提取任务中的表现，包括：
- Baichuan-M2
- DeepSeek-v3.1
- Doubao-seed-1-6
- GPT-5.1
- Grok-4
- Kimi-k2
- Qwen3-max

## 二、评测维度框架

### 2.1 核心评测维度（权重分配）

| 维度 | 权重 | 说明 |
|------|------|------|
| **准确性（Accuracy）** | 35% | 提取信息与原始对话的一致性 |
| **完整性（Completeness）** | 25% | 关键信息的覆盖程度 |
| **结构化质量（Structure）** | 15% | 输出格式的规范性和层次性 |
| **可读性（Readability）** | 10% | 语言表达的流畅性和专业性 |
| **一致性（Consistency）** | 10% | 多患者输出的格式一致性 |
| **鲁棒性（Robustness）** | 5% | 处理缺失/模糊信息的能力 |

### 2.2 辅助评测指标

- **效率指标**：平均响应时间、Token使用量
- **稳定性指标**：成功率、空输出率、错误率
- **成本指标**：每千次调用成本、每患者处理成本

## 三、具体评测方法

### 3.1 自动化评测（40%权重）

#### 3.1.1 结构完整性检测
```python
必需字段检查：
✓ 基本信息（性别、年龄、身高、体重）
✓ 主诉
✓ 现病史
✓ 既往病史
✓ 家族病史
评分：存在字段数 / 总字段数 × 100
```

#### 3.1.2 关键实体提取准确率
```python
预定义关键实体列表：
- 疾病名称（糖尿病、高血压等）
- 用药信息（药名、剂量、频次）
- 数值指标（血糖、体重、身高等）
- 时间信息（病程、用药时长等）

评分方法：
精确率 = 正确提取的实体数 / 总提取实体数
召回率 = 正确提取的实体数 / 应提取的实体总数
F1 = 2 × (精确率 × 召回率) / (精确率 + 召回率)
```

#### 3.1.3 数值信息准确性
```python
检查项：
- 年龄范围合理性
- 身高体重数值准确性
- 血糖数值准确性
- 病程时间准确性

评分：准确数值数 / 总数值数 × 100
```

#### 3.1.4 格式规范性评分
```python
检查项：
✓ Markdown格式正确性
✓ 标题层级规范性
✓ 列表格式统一性
✓ 特殊字符转义正确性

评分：符合规范项数 / 总检查项数 × 100
```

### 3.2 半自动化评测（30%权重）

#### 3.2.1 信息对齐度评分
```python
方法：使用语义相似度模型（如Sentence-BERT）
步骤：
1. 将原始对话分句
2. 将模型输出分句
3. 计算每个输出句子与原始对话的最大相似度
4. 平均相似度作为对齐度得分

评分范围：0-100
```

#### 3.2.2 关键词覆盖率
```python
预定义关键词库：
- 症状关键词（如：泡沫尿、体重下降、手麻等）
- 检查关键词（如：血糖、甘油三酯等）
- 治疗关键词（如：二甲双胍、胰岛素等）

评分：提取到的关键词数 / 应存在的关键词数 × 100
```

#### 3.2.3 逻辑一致性检测
```python
检查项：
- 时间线一致性（病程与事件时间点）
- 因果关系一致性（症状与诊断）
- 数值逻辑性（BMI与体重身高的匹配）

评分：一致性检查通过项 / 总检查项 × 100
```

### 3.3 人工评测（30%权重）

#### 3.3.1 评测量表设计

**维度1：准确性（1-5分）**
- 5分：所有信息完全准确，无错误
- 4分：绝大部分准确，有1-2处轻微错误
- 3分：基本准确，有3-4处错误
- 2分：多处错误，但核心信息基本正确
- 1分：大量错误或严重错误

**维度2：完整性（1-5分）**
- 5分：所有关键信息完整提取
- 4分：遗漏1-2个次要信息
- 3分：遗漏3-4个信息或1个重要信息
- 2分：遗漏多个重要信息
- 1分：大量关键信息缺失

**维度3：结构清晰度（1-5分）**
- 5分：结构非常清晰，层次分明
- 4分：结构清晰，少量格式问题
- 3分：结构基本清晰，有一定混乱
- 2分：结构较混乱，难以快速定位信息
- 1分：结构混乱，难以阅读

**维度4：语言质量（1-5分）**
- 5分：表达专业、流畅、简洁
- 4分：表达流畅，少量赘述
- 3分：表达基本清楚，有赘述或不够专业
- 2分：表达不够清晰，多处赘述
- 1分：表达混乱，难以理解

**维度5：临床实用性（1-5分）**
- 5分：完全符合临床使用需求，可直接使用
- 4分：基本符合需求，需少量修改
- 3分：需要一定修改才能使用
- 2分：需要大量修改
- 1分：不能直接用于临床

#### 3.3.2 评测流程
```
1. 随机抽样：每个模型随机抽取30%患者（3人）
2. 盲评：评测者不知道模型名称
3. 多评测者：至少3名医疗专业人员独立评分
4. 一致性检验：计算评测者间一致性（ICC）
5. 汇总：取平均分
```

## 四、评测执行计划

### 4.1 数据准备阶段
- [ ] 整理所有模型输出的Markdown文件
- [ ] 建立标准答案库（Golden Standard）
- [ ] 构建关键词词典
- [ ] 准备评测工具和脚本

### 4.2 自动化评测阶段
- [ ] 结构完整性批量检测
- [ ] 关键实体提取与匹配
- [ ] 数值准确性验证
- [ ] 格式规范性检查
- [ ] 生成自动化评测报告

### 4.3 半自动化评测阶段
- [ ] 语义相似度计算
- [ ] 关键词覆盖率分析
- [ ] 逻辑一致性检测
- [ ] 生成半自动化评测报告

### 4.4 人工评测阶段
- [ ] 组建评测团队（3-5名医疗专业人员）
- [ ] 培训评测标准
- [ ] 分配评测任务
- [ ] 收集评分数据
- [ ] 一致性分析
- [ ] 生成人工评测报告

### 4.5 综合分析阶段
- [ ] 汇总三类评测结果
- [ ] 计算加权总分
- [ ] 生成对比图表
- [ ] 撰写评测报告
- [ ] 提出改进建议

## 五、评测输出

### 5.1 数据输出

#### 5.1.1 原始评分表
```
模型 | 准确性 | 完整性 | 结构化 | 可读性 | 一致性 | 鲁棒性 | 总分
-----|--------|--------|--------|--------|--------|--------|------
M1   | 85     | 90     | 92     | 88     | 85     | 80     | 87.3
M2   | ...    | ...    | ...    | ...    | ...    | ...    | ...
```

#### 5.1.2 细分指标表
```
模型 | 实体F1 | 数值准确率 | 格式规范 | 相似度 | 关键词覆盖
-----|--------|------------|----------|--------|------------
M1   | 0.89   | 95%        | 92%      | 0.87   | 88%
M2   | ...    | ...        | ...      | ...    | ...
```

#### 5.1.3 效率指标表
```
模型 | 平均响应时间 | 平均Token | 成功率 | 每次成本
-----|--------------|-----------|--------|----------
M1   | 5.2s         | 1850      | 100%   | $0.05
M2   | ...          | ...       | ...    | ...
```

### 5.2 可视化输出

#### 5.2.1 雷达图
- 多维度能力对比（6个维度）
- 每个模型一条线
- 便于直观比较优劣势

#### 5.2.2 热力图
- 模型×患者表现矩阵
- 识别每个模型的强项患者类型
- 发现模型短板

#### 5.2.3 排名柱状图
- 总分排名
- 各维度排名
- 性价比排名

#### 5.2.4 散点图
- X轴：性能得分
- Y轴：成本
- 气泡大小：响应速度
- 识别最优性价比模型

### 5.3 报告输出

#### 5.3.1 执行摘要
- 最佳模型推荐（综合、准确性优先、成本优先）
- 关键发现
- 主要结论

#### 5.3.2 详细分析
- 各模型优劣势分析
- 典型案例对比
- 错误类型分析
- 改进方向建议

#### 5.3.3 附录
- 完整评分数据
- 评测方法说明
- 评测者背景
- 原始输出示例

## 六、评测工具设计

### 6.1 自动化评测脚本
```python
evaluation_toolkit/
├── auto_eval.py              # 自动化评测主脚本
├── structure_checker.py      # 结构完整性检查
├── entity_extractor.py       # 实体提取与匹配
├── numeric_validator.py      # 数值准确性验证
├── format_checker.py         # 格式规范性检查
└── utils.py                  # 工具函数
```

### 6.2 半自动化评测脚本
```python
evaluation_toolkit/
├── semi_auto_eval.py         # 半自动化评测主脚本
├── semantic_similarity.py    # 语义相似度计算
├── keyword_coverage.py       # 关键词覆盖率
├── logic_consistency.py      # 逻辑一致性检测
└── models/                   # 预训练模型
    └── sentence_bert/
```

### 6.3 人工评测界面
```python
evaluation_toolkit/
├── manual_eval_app.py        # Web评测界面（Streamlit/Gradio）
├── templates/                # HTML模板
├── database.py               # 评分数据存储
└── export.py                 # 结果导出
```

### 6.4 报告生成器
```python
evaluation_toolkit/
├── report_generator.py       # 报告生成主脚本
├── visualizer.py             # 图表生成
├── statistical_analysis.py  # 统计分析
└── templates/                # 报告模板
    ├── report_template.md
    └── charts/
```

## 七、标准答案库构建

### 7.1 Golden Standard格式
```json
{
  "patient_id": "患者1",
  "basic_info": {
    "gender": "男",
    "age": "50-55",
    "height": 182.0,
    "weight": 64.0
  },
  "chief_complaint": "配药",
  "present_illness": {
    "main_symptom": "小便泡沫多",
    "duration": "12年",
    "progression": "...",
    "key_events": [...]
  },
  "past_history": [...],
  "family_history": [...],
  "medications": [
    {
      "name": "二甲双胍",
      "dosage": "不详",
      "frequency": "早晚各一次"
    }
  ],
  "lab_results": {
    "fasting_glucose": "11 mmol/L"
  }
}
```

### 7.2 构建方法
1. 由3名医疗专业人员独立标注
2. 讨论不一致项达成共识
3. 形成最终标准答案
4. 用于自动化评测的ground truth

## 八、时间规划

| 阶段 | 任务 | 预计时间 |
|------|------|----------|
| 准备 | 数据整理、工具开发 | 3天 |
| 自动化评测 | 批量运行脚本 | 1天 |
| 半自动化评测 | 模型计算分析 | 1天 |
| 人工评测 | 组织评测、收集数据 | 5天 |
| 综合分析 | 汇总、可视化、报告 | 2天 |
| **总计** | | **12天** |

## 九、质量保证

### 9.1 评测可靠性
- 评测者间一致性检验（Kappa系数 > 0.7）
- 重测信度检验（抽取10%重新评测）
- 标准答案多人校验

### 9.2 评测有效性
- 评测指标与临床需求对齐
- 专家审核评测方案
- 试评测后调整标准

### 9.3 评测公平性
- 盲评机制
- 随机化患者分配
- 多模型交叉对比

## 十、后续改进方向

1. **持续评测**：建立持续评测流程，新模型上线即评测
2. **细分场景**：针对不同疾病类型、患者特征的专项评测
3. **A/B测试**：线上实际使用效果评测
4. **用户反馈**：收集真实医生使用反馈
5. **评测自动化**：完全自动化的CI/CD评测流程
