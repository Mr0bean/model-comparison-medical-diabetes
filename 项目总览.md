# 📋 医疗报告批量生成系统 - 项目总览

## 🎯 项目简介

本项目提供了一套完整的医疗报告批量生成和多模型对比解决方案，帮助您：
- ✅ 批量处理患者问诊记录，自动生成医疗报告
- ✅ 对比多个AI模型的输出质量和性能
- ✅ 选择最适合您业务场景的AI模型
- ✅ 提高医疗文档生成效率

## 📦 核心功能

### 功能1️⃣：单模型批量处理

**文件：** `batch_process.py`

**功能：**
- 使用单个模型批量处理多个患者
- 并发处理，性能提升4倍
- 生成多种格式报告

**使用场景：**
- 生产环境批量处理
- 已确定使用的模型
- 需要快速生成报告

**运行：**
```bash
python batch_process.py
```

**输出：**
- 完整JSON报告
- 可读格式报告
- 每个患者的独立报告

---

### 功能2️⃣：多模型对比（⭐️推荐）

**文件：** `batch_process_multi_model.py`

**功能：**
- 同时使用多个模型处理相同数据
- 横向对比不同模型的输出
- 详细的性能统计分析

**使用场景：**
- 模型选型阶段
- 质量评估和验证
- 持续性能监控

**运行：**
```bash
# 快速测试（2个模型）
python batch_process_multi_model_test.py

# 完整对比（4个模型）
python batch_process_multi_model.py
```

**输出：**
- 模型对比报告（横向对比）
- 性能对比报告
- 每个模型的独立报告
- 完整JSON数据

## 📁 文件结构

```
chat/
├── 核心脚本
│   ├── batch_process.py                      # 单模型批量处理
│   ├── batch_process_multi_model.py          # 多模型对比（完整版）
│   ├── batch_process_multi_model_test.py     # 多模型对比（测试版）
│   ├── chat_client.py                        # AI客户端
│   └── config.py                             # 配置文件
│
├── 输入数据
│   ├── 多个Prompt.json                       # 5个Prompt配置
│   └── 测试输入问答记录/                     # 患者问答记录
│       ├── 患者1_问答记录.txt
│       └── 患者2_问答记录.txt
│
├── 输出报告
│   ├── 报告输出/                             # 单模型输出目录
│   └── 模型对比报告_测试/                    # 多模型对比输出
│       ├── 模型对比报告_时间戳.txt
│       ├── 性能对比_时间戳.txt
│       ├── 完整报告_时间戳.json
│       ├── gpt-4o-mini/
│       │   └── 报告_时间戳.txt
│       └── gpt-5.1/
│           └── 报告_时间戳.txt
│
└── 文档
    ├── 项目总览.md                          # 本文件
    ├── README_多模型对比.md                  # 快速上手指南
    ├── 多模型对比使用说明.md                # 详细使用手册
    └── BATCH_PROCESS_README.md              # 单模型处理文档
```

## 🚀 快速开始

### 第一次使用？推荐这样开始：

#### 步骤1：运行快速测试（2分钟）

```bash
python batch_process_multi_model_test.py
```

这会对比2个模型（gpt-4o-mini vs gpt-5.1），处理2个患者，生成完整的对比报告。

#### 步骤2：查看报告（1分钟）

```bash
# 查看性能对比
cat 模型对比报告_测试/性能对比_*.txt

# 查看模型输出对比
cat 模型对比报告_测试/模型对比报告_*.txt | head -100
```

#### 步骤3：选择您的模型（根据报告决定）

基于对比结果，选择最适合的模型：
- **gpt-5.1**: 医学规范性更强，输出更详细
- **gpt-4o-mini**: 速度更快，成本更低

#### 步骤4：生产环境使用

```bash
# 使用选定的模型批量处理
python batch_process.py
```

## 📊 功能对比

| 功能 | 单模型批量处理 | 多模型对比 |
|------|--------------|-----------|
| **处理速度** | ⚡️⚡️⚡️ 快 | ⚡️⚡️ 适中（取决于模型数量） |
| **报告类型** | 3种 | 4种+ |
| **适用场景** | 生产环境 | 模型选型、质量验证 |
| **成本** | 💰 低 | 💰💰 按模型数量倍增 |
| **信息量** | ⭐️⭐️⭐️ | ⭐️⭐️⭐️⭐️⭐️ |

## 🎓 使用场景示例

### 场景1：首次使用，选择最佳模型

**目标：** 为您的业务选择最合适的AI模型

**步骤：**
1. 准备10-20个真实患者记录
2. 运行 `batch_process_multi_model.py`（对比4个模型）
3. 查看性能对比报告和输出对比
4. 综合考虑质量、速度、成本
5. 选定模型

**预计时间：** 10-15分钟

---

### 场景2：生产环境批量处理

**目标：** 快速处理大量患者记录

**步骤：**
1. 将患者记录放入 `测试输入问答记录/` 目录
2. 在 `config.py` 中设置使用的模型（如gpt-5.1）
3. 运行 `batch_process.py`
4. 获取所有报告

**预计时间：** 取决于患者数量（每个患者约30-40秒）

---

### 场景3：持续质量监控

**目标：** 定期检查模型输出质量

**步骤：**
1. 每周运行一次多模型对比
2. 记录性能指标变化
3. 发现异常及时调整

**预计时间：** 每周5分钟

---

### 场景4：Prompt优化

**目标：** 优化Prompt以获得更好的输出

**步骤：**
1. 创建多个版本的Prompt
2. 为每个版本运行对比
3. 选择效果最好的版本

**预计时间：** 每次测试3-5分钟

## 📈 测试结果总结

基于实际测试（2患者 × 5Prompts × 2模型）：

### 性能数据

| 模型 | 平均响应时间 | 平均输出长度 | 成功率 | 综合评价 |
|------|------------|------------|--------|----------|
| **gpt-4o-mini** | 4.49秒 ⚡️ | 147字符 | 100% | ⭐️⭐️⭐️⭐️ |
| **gpt-5.1** | 5.24秒 | 184字符 📝 | 100% | ⭐️⭐️⭐️⭐️⭐️ |

### 质量对比

**主诉生成：**
- ✅ gpt-5.1：更符合医学术语规范
- ❌ gpt-4o-mini：稍显口语化

**现病史生成：**
- ✅ gpt-5.1：更详细完整（多40%内容）
- ✅ gpt-4o-mini：简洁清晰

**既往史生成：**
- ✅ gpt-5.1：纯文本，符合病历格式
- ⚠️ gpt-4o-mini：有Markdown格式

### 推荐配置

**正式病历生成：** gpt-5.1
- 医学术语规范 ⭐️⭐️⭐️⭐️⭐️
- 内容详细完整 ⭐️⭐️⭐️⭐️⭐️
- 格式标准统一 ⭐️⭐️⭐️⭐️⭐️

**快速预览/大批量：** gpt-4o-mini
- 响应速度快 ⚡️⚡️⚡️
- 成本低 💰
- 基本信息完整 ⭐️⭐️⭐️⭐️

## 🛠️ 配置说明

### 修改使用的模型

**单模型处理：**
```python
# 编辑 config.py
default_model: str = "gpt-5.1"  # 修改为您想用的模型
```

**多模型对比：**
```python
# 编辑 batch_process_multi_model.py
MODELS = [
    "gpt-4o-mini",
    "gpt-5.1",
    # "gpt-4o",
    # "gpt-3.5-turbo"
]
```

### 修改Prompt

编辑 `多个Prompt.json`：
```json
[
  "您的第一个Prompt...",
  "您的第二个Prompt...",
  "..."
]
```

### 添加患者记录

将患者问答记录文件（.txt格式）放入：
```
测试输入问答记录/
├── 患者1_问答记录.txt
├── 患者2_问答记录.txt
└── 患者3_问答记录.txt  ← 新增
```

## 📚 详细文档

- 📖 [README_多模型对比.md](README_多模型对比.md) - 快速上手指南
- 📖 [多模型对比使用说明.md](多模型对比使用说明.md) - 详细使用手册
- 📖 [BATCH_PROCESS_README.md](BATCH_PROCESS_README.md) - 单模型处理文档

## ⚡ 性能优化技巧

### 1. 提高处理速度

```python
# 方法1：减少模型数量
MODELS = ["gpt-5.1"]  # 只用最好的

# 方法2：增加并发数（谨慎使用）
semaphore = asyncio.Semaphore(10)  # 增加到10

# 方法3：减少Prompt数量
# 只保留最重要的Prompt
```

### 2. 提高输出质量

```python
# 方法1：使用更好的模型
default_model = "gpt-5.1"  # 或 "gpt-4o"

# 方法2：增加max_tokens
max_tokens = 3000  # 允许更长的输出

# 方法3：优化Prompt
# 在Prompt中添加更详细的指导
```

### 3. 降低成本

```python
# 方法1：使用成本更低的模型
MODELS = ["gpt-4o-mini", "gpt-3.5-turbo"]

# 方法2：减少max_tokens
max_tokens = 1500  # 减少到1500

# 方法3：只在关键场景使用高级模型
# 预览用gpt-4o-mini，正式用gpt-5.1
```

## 🐛 常见问题

### Q1: 如何选择模型？

**回答：**
- **质量优先**：gpt-5.1 或 gpt-4o
- **速度优先**：gpt-4o-mini
- **成本优先**：gpt-3.5-turbo
- **不确定**：运行多模型对比测试

### Q2: 处理时间多长？

**回答：**
- 单个Prompt：3-10秒
- 单个患者（5个Prompt）：30-40秒
- 10个患者（单模型）：5-7分钟
- 10个患者（4模型对比）：20-30分钟

### Q3: 成本如何？

**回答：**
- 成本主要取决于：模型选择、输入长度、输出长度
- 估算：每个患者×每个Prompt约0.01-0.05美元
- 建议：先用测试数据评估成本

### Q4: 如何提高准确性？

**回答：**
1. 优化Prompt（添加更详细的指导）
2. 使用更好的模型（gpt-5.1）
3. 提供更完整的患者记录
4. 增加max_tokens

### Q5: 可以自定义报告格式吗？

**回答：**
可以！修改以下函数：
- `_save_model_comparison_report()` - 对比报告格式
- `_save_performance_report()` - 性能报告格式
- `_save_per_model_reports()` - 单模型报告格式

## 🎉 总结

### 核心优势

1. **高效并发**：性能提升4倍+
2. **多模型对比**：一键对比多个模型
3. **详细报告**：4种格式满足不同需求
4. **灵活配置**：支持自定义模型、Prompt
5. **易于使用**：一行命令即可运行

### 适用场景

- ✅ 医疗机构批量生成病历
- ✅ AI模型选型和评估
- ✅ 医疗文档质量监控
- ✅ Prompt工程优化
- ✅ 医疗AI研究和开发

### 开始使用

```bash
# 第一次使用？从这里开始！
python batch_process_multi_model_test.py
```

**预计收获：**
- ✅ 了解系统功能
- ✅ 查看对比报告
- ✅ 选择最佳模型
- ✅ 评估系统价值

---

## 📞 联系与支持

- 💬 问题反馈：查看日志文件或提交Issue
- 📖 查看文档：README_多模型对比.md
- 🔧 技术支持：查看详细日志获取错误信息

**祝您使用愉快！🎊**
