#!/usr/bin/env python3
"""
çµæ´»çš„åˆ†æ‰¹è¯„ä¼°è„šæœ¬
å¯ä»¥è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°ã€æŒ‰æ¨¡å‹åˆ†æ‰¹ã€æŒ‰æ‚£è€…åˆ†æ‰¹
"""

import argparse
import subprocess
import time
from datetime import datetime
from typing import List


def chunk_list(lst: List, chunk_size: int) -> List[List]:
    """å°†åˆ—è¡¨åˆ†æˆæŒ‡å®šå¤§å°çš„å—"""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]


def run_evaluation_chunk(patients: List[str], models: List[str] = None, dry_run: bool = False):
    """è¿è¡Œä¸€ä¸ªæ‰¹æ¬¡çš„è¯„ä¼°"""
    cmd = ["python", "run_cross_evaluation.py", "--patients"] + patients

    if models:
        cmd.extend(["--models"] + models)

    print(f"\n{'='*80}")
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print(f"æ‚£è€…: {', '.join(patients)}")
    if models:
        print(f"æ¨¡å‹: {', '.join(models)}")
    print(f"é¢„è®¡è¯„ä¼°: {len(patients)} Ã— {len(models) if models else 8} Ã— {len(models) if models else 8} = {len(patients) * (len(models) if models else 8) * (len(models) if models else 8)} æ¬¡")
    print(f"{'='*80}\n")

    if dry_run:
        print("âš ï¸  è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œ\n")
        return {"status": "dry_run"}

    start_time = time.time()

    try:
        result = subprocess.run(cmd, check=True)
        duration = time.time() - start_time

        print(f"\nâœ… æ‰¹æ¬¡æ‰§è¡ŒæˆåŠŸ (è€—æ—¶: {duration/60:.1f} åˆ†é’Ÿ)")
        return {"status": "success", "duration": duration}

    except subprocess.CalledProcessError as e:
        print(f"\nâŒ æ‰¹æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
        return {"status": "failed", "error": str(e)}


def main():
    parser = argparse.ArgumentParser(description="çµæ´»çš„åˆ†æ‰¹è¯„ä¼°è„šæœ¬")

    parser.add_argument(
        "--batch-size",
        type=int,
        default=3,
        help="æ¯æ‰¹åŒ…å«çš„æ‚£è€…æ•°é‡ï¼ˆé»˜è®¤: 3ï¼‰"
    )

    parser.add_argument(
        "--patients",
        nargs="+",
        default=[f"æ‚£è€…{i}" for i in range(1, 11)],
        help="è¦è¯„ä¼°çš„æ‚£è€…åˆ—è¡¨ï¼ˆé»˜è®¤: æ‚£è€…1-10ï¼‰"
    )

    parser.add_argument(
        "--models",
        nargs="+",
        help="è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆé»˜è®¤: å…¨éƒ¨ï¼‰"
    )

    parser.add_argument(
        "--batch-index",
        type=int,
        help="åªæ‰§è¡ŒæŒ‡å®šæ‰¹æ¬¡ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œä¸æŒ‡å®šåˆ™æ‰§è¡Œå…¨éƒ¨"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œæ¨¡å¼ï¼Œä»…æ˜¾ç¤ºå‘½ä»¤ä¸æ‰§è¡Œ"
    )

    parser.add_argument(
        "--wait-time",
        type=int,
        default=5,
        help="æ‰¹æ¬¡é—´ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤: 5ï¼‰"
    )

    args = parser.parse_args()

    # åˆ†æ‰¹
    patient_chunks = chunk_list(args.patients, args.batch_size)

    print("\n" + "="*80)
    print("ğŸ“Š çµæ´»åˆ†æ‰¹è¯„ä¼°ç³»ç»Ÿ")
    print("="*80)
    print(f"\næ€»æ‚£è€…æ•°: {len(args.patients)}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"æ€»æ‰¹æ¬¡æ•°: {len(patient_chunks)}")
    print(f"\næ‰¹æ¬¡åˆ’åˆ†:")

    for i, chunk in enumerate(patient_chunks, 1):
        print(f"  æ‰¹æ¬¡{i}: {', '.join(chunk)}")

    if args.models:
        print(f"\næŒ‡å®šæ¨¡å‹: {', '.join(args.models)}")

    # ç¡®å®šè¦æ‰§è¡Œçš„æ‰¹æ¬¡
    if args.batch_index:
        if args.batch_index < 1 or args.batch_index > len(patient_chunks):
            print(f"\nâŒ é”™è¯¯: æ‰¹æ¬¡ç´¢å¼• {args.batch_index} è¶…å‡ºèŒƒå›´ (1-{len(patient_chunks)})")
            return

        chunks_to_run = [patient_chunks[args.batch_index - 1]]
        print(f"\nä»…æ‰§è¡Œæ‰¹æ¬¡ {args.batch_index}")
    else:
        chunks_to_run = patient_chunks
        print(f"\næ‰§è¡Œå…¨éƒ¨ {len(chunks_to_run)} ä¸ªæ‰¹æ¬¡")

    # è¯¢é—®ç¡®è®¤
    if not args.dry_run:
        print("\n" + "="*80)
        choice = input("æ˜¯å¦å¼€å§‹æ‰§è¡Œï¼Ÿ(y/n): ")
        if choice.lower() != 'y':
            print("å·²å–æ¶ˆæ‰§è¡Œ")
            return

    # æ‰§è¡Œæ‰¹æ¬¡
    results = []
    overall_start_time = time.time()

    for i, chunk in enumerate(chunks_to_run, 1):
        print(f"\n{'='*80}")
        print(f"è¿›åº¦: {i}/{len(chunks_to_run)}")
        print(f"{'='*80}")

        result = run_evaluation_chunk(
            patients=chunk,
            models=args.models,
            dry_run=args.dry_run
        )
        results.append(result)

        # æ‰¹æ¬¡é—´ç­‰å¾…
        if i < len(chunks_to_run) and not args.dry_run:
            print(f"\nç­‰å¾… {args.wait_time} ç§’åæ‰§è¡Œä¸‹ä¸€æ‰¹...")
            time.sleep(args.wait_time)

    # æ€»ç»“
    overall_duration = time.time() - overall_start_time

    print("\n" + "="*80)
    print("ğŸ“Š æ‰§è¡Œæ€»ç»“")
    print("="*80)

    successful = sum(1 for r in results if r['status'] == 'success')
    failed = sum(1 for r in results if r['status'] == 'failed')

    print(f"\næ‰§è¡Œæ‰¹æ¬¡æ•°: {len(results)}/{len(chunks_to_run)}")
    print(f"æˆåŠŸ: {successful}")
    print(f"å¤±è´¥: {failed}")
    print(f"æ€»è€—æ—¶: {overall_duration/60:.1f} åˆ†é’Ÿ")

    # ä¿å­˜æ—¥å¿—
    if not args.dry_run:
        log_file = f"flexible_batch_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"çµæ´»åˆ†æ‰¹è¯„ä¼°æ‰§è¡Œæ—¥å¿—\n")
            f.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}\n")
            f.write(f"æ€»æ‰¹æ¬¡æ•°: {len(results)}\n")
            f.write(f"æ€»è€—æ—¶: {overall_duration/60:.1f} åˆ†é’Ÿ\n\n")

            for i, (chunk, result) in enumerate(zip(chunks_to_run, results), 1):
                f.write(f"\næ‰¹æ¬¡{i}:\n")
                f.write(f"  æ‚£è€…: {', '.join(chunk)}\n")
                f.write(f"  çŠ¶æ€: {result['status']}\n")
                if 'duration' in result:
                    f.write(f"  è€—æ—¶: {result['duration']/60:.1f} åˆ†é’Ÿ\n")

        print(f"\nğŸ“ æ‰§è¡Œæ—¥å¿—å·²ä¿å­˜: {log_file}")

    print("="*80 + "\n")


if __name__ == "__main__":
    main()
